import React, { useState, useRef, useEffect } from 'react';
import { Mic, MicOff, MessageSquare, Loader } from 'lucide-react';
import type { AppState } from '../App';
import { processVoiceCommand, generateStepGuidance } from '../services/geminiService';
import { translateText, getLanguageFromText, supportedLanguages } from '../services/languageService';
              <button
                key={code}
                onClick={() => {
                  updateAppState({ currentLanguage: code });
                  // Update speech recognition language
                  if (recognitionRef.current) {
                    recognitionRef.current.lang = lang.speechCode;
                  }
                }}
                className={`text-xs py-2 px-3 rounded transition-all duration-200 ${
                  appState.currentLanguage === code
                    ? 'bg-blue-600 text-white'
                    : 'bg-white/5 text-white/70 hover:bg-white/10 hover:text-white'
                }`}
              >
                {lang.nativeName}
              </button>
            ))}e VoiceCommandProps {
  appState: AppState;
  updateAppState: (updates: Partial<AppState>) => void;
  apiKey: string;
}

declare global {
  interface Window {
    SpeechRecognition: any;
    webkitSpeechRecognition: any;
  }
}

export const VoiceCommand: React.FC<VoiceCommandProps> = ({ appState, updateAppState, apiKey }) => {
  const [transcript, setTranscript] = useState('');
  const [isSupported, setIsSupported] = useState(true);
  const [voiceGuidance, setVoiceGuidance] = useState<string>('');
  const recognitionRef = useRef<any>(null);
  const speechSynthesisRef = useRef<SpeechSynthesisUtterance | null>(null);

  useEffect(() => {
    // Check if Speech Recognition is supported
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    
    if (!SpeechRecognition) {
      setIsSupported(false);
      return;
    }

    const recognition = new SpeechRecognition();
    recognition.continuous = true;
    recognition.interimResults = true;
    recognition.lang = appState.currentLanguage ? 
      supportedLanguages[appState.currentLanguage]?.speechCode || 'en-US' : 'en-US';

    recognition.onstart = () => {
      updateAppState({ isListening: true });
    };

    recognition.onresult = (event: any) => {
      let finalTranscript = '';
      let interimTranscript = '';

      for (let i = event.resultIndex; i < event.results.length; i++) {
        const transcript = event.results[i][0].transcript;
        if (event.results[i].isFinal) {
          finalTranscript += transcript;
        } else {
          interimTranscript += transcript;
        }
      }

      setTranscript(finalTranscript || interimTranscript);
      
      if (finalTranscript) {
        handleVoiceCommand(finalTranscript);
      }
    };

    recognition.onerror = (event: any) => {
      console.error('Speech recognition error:', event.error);
      updateAppState({ isListening: false });
    };

    recognition.onend = () => {
      updateAppState({ isListening: false });
    };

    recognitionRef.current = recognition;

    return () => {
      if (recognitionRef.current) {
        recognitionRef.current.stop();
      }
    };
  }, [appState.currentLanguage]); // Add currentLanguage as dependency

  // Voice guidance effect
  useEffect(() => {
    if (appState.tutorialSteps.length > 0 && appState.currentStep < appState.tutorialSteps.length) {
      const currentStepData = appState.tutorialSteps[appState.currentStep];
      provideVoiceGuidance(currentStepData.action, currentStepData.description);
    }
  }, [appState.currentStep, appState.tutorialSteps]);

  const handleVoiceCommand = async (command: string) => {
    console.log('Voice command received:', command);
    console.log('App state - isScreenSharing:', appState.isScreenSharing);
    console.log('App state - screenStream:', appState.screenStream);
    
    // Detect language from the command
    const detectedLanguage = getLanguageFromText(command);
    console.log('Detected language:', detectedLanguage);
    
    // Update the app state with detected language
    updateAppState({ 
      currentLanguage: detectedLanguage.code,
      detectedLanguageCode: detectedLanguage.code 
    });
    
    // Temporary override for testing - remove this later
    const hasScreenShare = appState.isScreenSharing || appState.screenStream || true; // Force true for testing
    
    if (!hasScreenShare) {
      const message = translateText('Please start screen sharing first to use voice commands.', detectedLanguage.code);
      speakText(message, detectedLanguage.speechCode);
      setVoiceGuidance(message);
      return;
    }

    updateAppState({ 
      currentCommand: command,
      isProcessing: true 
    });

    try {
      // Process the command and determine if we need to navigate to a specific website
      const response = await processVoiceCommand(command, apiKey, detectedLanguage.code);
      
      if (response) {
        // Check if this is a web-based task (like Gmail)
        const websiteTarget = detectWebsiteTarget(command);
        
        if (websiteTarget) {
          // Provide guidance to navigate to the website first
          const navigationMessage = translateText(`To ${command}, let's first navigate to ${websiteTarget.name}. Please open your browser and go to ${websiteTarget.url}`, detectedLanguage.code, {
            TASK: command,
            WEBSITE: websiteTarget.name,
            URL: websiteTarget.url
          });
          speakText(navigationMessage, detectedLanguage.speechCode);
          
          updateAppState({
            currentWebsite: websiteTarget.url,
            tutorialSteps: [
              {
                id: 'navigate-to-site',
                command,
                description: translateText(`Navigate to ${websiteTarget.name}`, detectedLanguage.code, {
                  WEBSITE: websiteTarget.name
                }),
                coordinates: { x: 400, y: 300 },
                action: translateText(`Open ${websiteTarget.url}`, detectedLanguage.code, {
                  URL: websiteTarget.url
                }),
                completed: false
              },
              ...response.steps
            ],
            currentStep: 0,
            isProcessing: false
          });
        } else {
          updateAppState({
            tutorialSteps: response.steps,
            currentStep: 0,
            isProcessing: false
          });
        }
      }
    } catch (error) {
      console.error('Error processing voice command:', error);
      const errorMessage = translateText('Sorry, I encountered an error processing your command. Please try again.', detectedLanguage.code);
      speakText(errorMessage, detectedLanguage.speechCode);
      updateAppState({ isProcessing: false });
    }
  };

  const detectWebsiteTarget = (command: string) => {
    const lowerCommand = command.toLowerCase();
    
    // English patterns
    if (lowerCommand.includes('gmail') || lowerCommand.includes('send email') || lowerCommand.includes('compose email')) {
      return { name: 'Gmail', url: 'https://gmail.com' };
    }
    
    // Hindi patterns
    if (lowerCommand.includes('‡§ú‡•Ä‡§Æ‡•á‡§≤') || lowerCommand.includes('‡§à‡§Æ‡•á‡§≤ ‡§≠‡•á‡§ú‡§®‡§æ') || lowerCommand.includes('‡§Æ‡•á‡§≤ ‡§≤‡§ø‡§ñ‡§®‡§æ')) {
      return { name: 'Gmail', url: 'https://gmail.com' };
    }
    
    // Universal patterns for other apps
    if (lowerCommand.includes('google docs') || lowerCommand.includes('document') || lowerCommand.includes('‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º')) {
      return { name: 'Google Docs', url: 'https://docs.google.com' };
    }
    if (lowerCommand.includes('youtube') || lowerCommand.includes('‡§Ø‡•Ç‡§ü‡•ç‡§Ø‡•Ç‡§¨')) {
      return { name: 'YouTube', url: 'https://youtube.com' };
    }
    if (lowerCommand.includes('facebook') || lowerCommand.includes('‡§´‡•á‡§∏‡§¨‡•Å‡§ï')) {
      return { name: 'Facebook', url: 'https://facebook.com' };
    }
    
    return null;
  };

  const provideVoiceGuidance = async (action: string, description: string) => {
    const currentLang = appState.currentLanguage || 'en';
    const guidance = await generateStepGuidance(action, description, apiKey, currentLang);
    const translatedGuidance = translateText(guidance, currentLang);
    setVoiceGuidance(translatedGuidance);
    speakText(translatedGuidance);
  };

  const speakText = (text: string, languageCode?: string) => {
    if ('speechSynthesis' in window) {
      // Cancel any ongoing speech
      window.speechSynthesis.cancel();
      
      const utterance = new SpeechSynthesisUtterance(text);
      utterance.rate = 0.9;
      utterance.pitch = 1;
      utterance.volume = 0.8;
      
      // Set language if provided
      if (languageCode) {
        utterance.lang = languageCode;
      } else if (appState.currentLanguage) {
        const langSupport = supportedLanguages[appState.currentLanguage];
        if (langSupport) {
          utterance.lang = langSupport.speechCode;
        }
      }
      
      speechSynthesisRef.current = utterance;
      window.speechSynthesis.speak(utterance);
    }
  };

  const nextStep = () => {
    if (appState.currentStep < appState.tutorialSteps.length - 1) {
      updateAppState({ currentStep: appState.currentStep + 1 });
    } else {
      const congratsMessage = translateText('Congratulations! You have completed all the steps.', appState.currentLanguage || 'en');
      speakText(congratsMessage);
      updateAppState({ tutorialSteps: [], currentStep: 0 });
    }
  };

  const repeatGuidance = () => {
    if (voiceGuidance) {
      speakText(voiceGuidance);
    }
  };

  const skipStep = () => {
    nextStep();
  };

  const startListening = () => {
    if (recognitionRef.current && !appState.isListening) {
      setTranscript('');
      recognitionRef.current.start();
    }
  };

  const stopListening = () => {
    if (recognitionRef.current && appState.isListening) {
      recognitionRef.current.stop();
    }
  };

  if (!isSupported) {
    return (
      <div className="bg-white/5 backdrop-blur-lg rounded-2xl p-6 border border-white/10">
        <div className="text-center">
          <MicOff className="w-12 h-12 text-red-400 mx-auto mb-4" />
          <h3 className="text-lg font-semibold text-white mb-2">Voice Recognition Not Supported</h3>
          <p className="text-white/60 text-sm">
            Your browser doesn't support speech recognition. Please use a modern browser like Chrome.
          </p>
        </div>
      </div>
    );
  }

  return (
    <div className="bg-white/5 backdrop-blur-lg rounded-2xl p-6 border border-white/10">
      <div className="flex items-center space-x-3 mb-6">
        <Mic className="w-6 h-6 text-green-400" />
        <h2 className="text-xl font-semibold text-white">Voice Commands</h2>
      </div>

      <div className="space-y-4">
        {/* Voice Control Button */}
        <div className="text-center">
          <button
            onClick={appState.isListening ? stopListening : startListening}
            disabled={appState.isProcessing || !appState.isScreenSharing || !appState.screenStream}
            className={`w-20 h-20 rounded-full flex items-center justify-center transition-all duration-200 transform hover:scale-105 ${
              appState.isListening
                ? 'bg-gradient-to-br from-red-500 to-red-600 shadow-lg shadow-red-500/25'
                : 'bg-gradient-to-br from-green-500 to-green-600 shadow-lg shadow-green-500/25'
            } ${
              (appState.isProcessing || !appState.isScreenSharing || !appState.screenStream) 
                ? 'opacity-50 cursor-not-allowed' 
                : 'cursor-pointer'
            }`}
          >
            {appState.isProcessing ? (
              <Loader className="w-8 h-8 text-white animate-spin" />
            ) : appState.isListening ? (
              <MicOff className="w-8 h-8 text-white" />
            ) : (
              <Mic className="w-8 h-8 text-white" />
            )}
          </button>
          
          <p className="text-white/60 text-sm mt-3">
            {appState.isProcessing 
              ? 'Processing with AI...'
              : appState.isListening 
                ? 'Listening...'
                : (!appState.isScreenSharing || !appState.screenStream)
                  ? 'Start screen sharing first'
                  : 'Click to start voice command'
            }
          </p>
        </div>

        {/* Transcript Display */}
        {(transcript || appState.currentCommand) && (
          <div className="bg-white/5 rounded-lg p-4 border border-white/10">
            <div className="flex items-start space-x-3">
              <MessageSquare className="w-5 h-5 text-blue-400 mt-0.5" />
              <div>
                <p className="text-white/80 text-sm font-medium">
                  {appState.isProcessing ? 'Processing:' : 'You said:'}
                </p>
                <p className="text-white mt-1">
                  {transcript || appState.currentCommand}
                </p>
              </div>
            </div>
          </div>
        )}

        {/* Language Selector */}
        <div className="bg-white/5 rounded-lg p-4 border border-white/10 mb-4">
          <h4 className="text-white/80 font-medium mb-3">üåç Language / ‡§≠‡§æ‡§∑‡§æ / Idioma</h4>
          <div className="grid grid-cols-2 gap-2">
            {Object.entries(supportedLanguages).slice(0, 6).map(([code, lang]) => (
              <button
                key={code}
                onClick={() => {
                  updateAppState({ currentLanguage: code });
                  // Update speech recognition language
                  if (recognitionRef.current) {
                    recognitionRef.current.lang = lang.speechCode;
                  }
                }}
                className={`text-xs py-2 px-3 rounded transition-all duration-200 ${
                  appState.currentLanguage === code
                    ? 'bg-blue-600 text-white'
                    : 'bg-white/5 text-white/70 hover:bg-white/10 hover:text-white'
                }`}
              >
                {lang.nativeName}
              </button>
            ))}
          </div>
        </div>

        {/* Example Commands */}
        <div className="bg-white/5 rounded-lg p-4 border border-white/10">
          <h4 className="text-white/80 font-medium mb-3">Try these commands:</h4>
          
          {/* Test Phantom AI Button */}
          <button
            onClick={() => {
              updateAppState({ 
                currentCommand: 'How to compose an email in Gmail',
                detectedApplication: 'Gmail'
              });
            }}
            className="w-full mb-3 bg-purple-600 hover:bg-purple-700 text-white text-sm font-medium py-2 px-3 rounded transition-colors"
          >
            üé≠ Test Phantom AI (Gmail)
          </button>
          
          <div className="space-y-2">
            {[
              { en: "How to compose an email in Gmail", hi: "Gmail ‡§Æ‡•á‡§Ç ‡§à‡§Æ‡•á‡§≤ ‡§ï‡•à‡§∏‡•á ‡§≤‡§ø‡§ñ‡•á‡§Ç", es: "C√≥mo redactar un correo en Gmail" },
              { en: "Show me how to create a Google document", hi: "Google ‡§¶‡§∏‡•ç‡§§‡§æ‡§µ‡•á‡§ú‡§º ‡§ï‡•à‡§∏‡•á ‡§¨‡§®‡§æ‡§è‡§Ç", es: "C√≥mo crear un documento de Google" },
              { en: "How to delete a photo in gallery", hi: "‡§ó‡•à‡§≤‡§∞‡•Ä ‡§Æ‡•á‡§Ç ‡§´‡•ã‡§ü‡•ã ‡§ï‡•à‡§∏‡•á ‡§°‡§ø‡§≤‡•Ä‡§ü ‡§ï‡§∞‡•á‡§Ç", es: "C√≥mo eliminar una foto de la galer√≠a" },
              { en: "Help me send a message on Facebook", hi: "Facebook ‡§™‡§∞ ‡§∏‡§Ç‡§¶‡•á‡§∂ ‡§ï‡•à‡§∏‡•á ‡§≠‡•á‡§ú‡•á‡§Ç", es: "C√≥mo enviar un mensaje en Facebook" },
              { en: "How to create a new folder", hi: "‡§®‡§Ø‡§æ ‡§´‡•ã‡§≤‡•ç‡§°‡§∞ ‡§ï‡•à‡§∏‡•á ‡§¨‡§®‡§æ‡§è‡§Ç", es: "C√≥mo crear una nueva carpeta" }
            ].map((commandSet, index) => {
              const currentLang = appState.currentLanguage || 'en';
              const command = commandSet[currentLang as keyof typeof commandSet] || commandSet.en;
              
              return (
                <button
                  key={index}
                  onClick={() => handleVoiceCommand(command)}
                  disabled={appState.isProcessing || !appState.isScreenSharing || !appState.screenStream}
                  className="block w-full text-left text-white/60 hover:text-white text-sm p-2 rounded hover:bg-white/5 transition-all duration-200 disabled:opacity-50 disabled:cursor-not-allowed"
                >
                  "{command}"
                </button>
              );
            })}
          </div>
        </div>

        {/* Current Tutorial Progress */}
        {appState.tutorialSteps.length > 0 && (
          <div className="bg-white/5 rounded-lg p-4 border border-white/10">
            <h4 className="text-white/80 font-medium mb-3">Tutorial Progress</h4>
            <div className="space-y-2">
              <div className="flex justify-between items-center text-sm">
                <span className="text-white/60">
                  Step {appState.currentStep + 1} of {appState.tutorialSteps.length}
                </span>
                <span className="text-green-400">
                  {Math.round(((appState.currentStep) / appState.tutorialSteps.length) * 100)}% Complete
                </span>
              </div>
              
              {appState.tutorialSteps[appState.currentStep] && (
                <div className="bg-white/5 p-3 rounded">
                  <p className="text-white font-medium text-sm mb-1">
                    {appState.tutorialSteps[appState.currentStep].action}
                  </p>
                  <p className="text-white/70 text-xs">
                    {appState.tutorialSteps[appState.currentStep].description}
                  </p>
                </div>
              )}
              
              <div className="flex space-x-2 mt-3">
                <button
                  onClick={repeatGuidance}
                  className="flex-1 bg-blue-500/20 text-blue-400 hover:bg-blue-500/30 px-3 py-2 rounded text-sm font-medium transition-all duration-200"
                >
                  üîä Repeat
                </button>
                <button
                  onClick={nextStep}
                  className="flex-1 bg-green-500/20 text-green-400 hover:bg-green-500/30 px-3 py-2 rounded text-sm font-medium transition-all duration-200"
                >
                  ‚úì Done
                </button>
                <button
                  onClick={skipStep}
                  className="flex-1 bg-yellow-500/20 text-yellow-400 hover:bg-yellow-500/30 px-3 py-2 rounded text-sm font-medium transition-all duration-200"
                >
                  ‚è≠ Skip
                </button>
              </div>
            </div>
          </div>
        )}

        {/* Voice Guidance Display */}
        {voiceGuidance && (
          <div className="bg-green-500/10 border border-green-500/20 rounded-lg p-4">
            <div className="flex items-start space-x-3">
              <div className="w-6 h-6 bg-green-500 rounded-full flex items-center justify-center flex-shrink-0">
                <span className="text-white text-xs">üéô</span>
              </div>
              <div>
                <p className="text-green-400 text-sm font-medium mb-1">AI Voice Guidance</p>
                <p className="text-white text-sm">{voiceGuidance}</p>
              </div>
            </div>
          </div>
        )}
      </div>
    </div>
  );
};